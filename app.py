# --- 1) Imports y configuraci√≥n ---
import streamlit as st
import requests
import pandas as pd
import matplotlib.pyplot as plt

st.set_page_config(page_title="SemitIA Dashboard", layout="wide")

# --- 2) Secrets (backend URL y token) ---
API_BASE = st.secrets.get("API_BASE", "http://localhost:8001")
API_TOKEN = st.secrets.get("API_TOKEN", None)

HEADERS = {"Content-Type": "application/json"}
if API_TOKEN:
    HEADERS["Authorization"] = f"Bearer {API_TOKEN}"

# --- 3) Sidebar (selector de modo) ---
st.sidebar.title("SemitIA")
mode = st.sidebar.radio("Modo", ["CSV", "Clasificaci√≥n en vivo", "Estad√≠sticas"], index=0)

# --- 4) Modo CSV: carga y visualizaci√≥n del dataset clasificado ---
if mode == "CSV":
    st.title("üìä SemitIA Dashboard ‚Äì An√°lisis IHRA de Tuits")
    st.caption("Clasificaci√≥n autom√°tica de antisemitismo (0‚Äì3) seg√∫n IHRA")

    uploaded = st.file_uploader("üìÅ Sub√≠ tu CSV clasificado", type=["csv"])
    if uploaded:
        df = pd.read_csv(uploaded)

        # Validaciones suaves
        cols_requeridas = {"texto", "etiqueta_gpt", "subtipo_gpt", "confidence_gpt", "reason_gpt"}
        faltantes = cols_requeridas - set(df.columns)
        if faltantes:
            st.error(f"Faltan columnas en el CSV: {', '.join(sorted(faltantes))}")
        else:
            st.subheader("Datos generales")
            st.write(f"Tuits analizados: {len(df)}")

            # Distribuci√≥n general (sin colores expl√≠citos)
            st.subheader("Distribuci√≥n de clasificaciones (IHRA 0‚Äì3)")
            conteo = df["etiqueta_gpt"].value_counts().sort_index()
            fig, ax = plt.subplots()
            ax.bar(conteo.index.astype(str), conteo.values)
            ax.set_xlabel("Categor√≠a IHRA (0‚Äì3)")
            ax.set_ylabel("Cantidad de tuits")
            st.pyplot(fig)

            # Filtro por categor√≠a
            opciones = sorted(df["etiqueta_gpt"].dropna().unique())
            opcion = st.selectbox("üîç Filtrar por categor√≠a (0‚Äì3):", opciones)
            filtrados = df[df["etiqueta_gpt"] == opcion]
            st.write(f"Mostrando {len(filtrados)} tuits")
            st.dataframe(filtrados[["texto", "subtipo_gpt", "confidence_gpt", "reason_gpt"]])
    else:
        st.info("‚¨ÜÔ∏è Sub√≠ un CSV con tus clasificaciones (por ejemplo, `tuits_clasificados_final.csv`).")

# --- 5) Modo Clasificaci√≥n en vivo: usa tu backend /api/classify ---
elif mode == "Clasificaci√≥n en vivo":
    st.header("üîé Clasificaci√≥n IHRA en vivo")
    texto = st.text_area("Peg√° un tuit o texto corto en espa√±ol", height=140)

    col_a, col_b = st.columns([1, 3])
    with col_a:
        lanzar = st.button("Clasificar", type="primary")

    if lanzar:
        if not texto.strip():
            st.warning("Peg√° un texto primero.")
        else:
            with st.spinner("Clasificando..."):
                try:
                    r = requests.post(f"{API_BASE}/api/classify", headers=HEADERS, json={"text": texto}, timeout=30)
                except Exception as e:
                    st.error(f"No se pudo conectar al backend: {e}")
                    st.stop()

            if r.status_code != 200:
                st.error(f"Error {r.status_code}: {r.text}")
            else:
                data = r.json()
                # M√©tricas
                col1, col2, col3 = st.columns(3)
                col1.metric("Nivel IHRA", data.get("label"))
                conf = data.get("confidence")
                col2.metric("Confianza", f"{conf*100:.1f}%" if isinstance(conf, (int, float)) else "‚Äî")
                col3.metric("Tiempo", f"{data.get('elapsed_ms', 0)} ms")

                # Detalle
               
